---
title: "Bayesian Modeling"
author: "Ben Gerber"
format: pdf
editor: visual
---

## Load Libraries, Data, and Show Data Structure and Preliminary Missing

```{r}
library(tidyverse)
library(RSocrata)
library(gtsummary)
library(brms)
library(tidybayes)
library(modelr)
library(mice)
library(posterior)
library(usmap)
```


```{r}
#df <- read.socrata(
#  url = "https://data.cdc.gov/resource/n8mc-b4w4.json?$limit=100000"
#)

load("/Users/lukewilsen/Desktop/School/BS_730/BS_730_proj/730_data_150000_obs.RData")

str(df)
```

{{< pagebreak >}}

## Convert "Missing" and "Unknown" text to NA, make age ordinal

```{r}
df_recode <- df |>
  mutate(across(everything(), ~if_else(. %in% c("Unknown", "Missing", "NA"), NA_character_, .))) |>
  mutate(hosp_yn = factor(hosp_yn, levels = c("No", "Yes")))

df_recode$age_group <- ordered(df_recode$age_group)

```

{{< pagebreak >}}

## Make an Example Bayesian Model with Age and Race Only

```{r}
mod_1 <- brm(
  hosp_yn ~ age_group + race,
  data = df_recode,
  iter = 1000,
  chains = 4,
  cores = getOption("mc.cores", 4),
  family = bernoulli
)
```

### Results Summary

```{r}
summary(mod_1)
```

Noted increased risk of hospitalization with older age, and decreased risk with White race.

The ordinal age group gives contrasts for linear, quadratic and cubic (linear significant).

### Check Posterior Distributions and Chains Mixing

```{r}
plot(mod_1)
```

{{< pagebreak >}}

## Make a hierarchical model with state

Added more iterations given lower effect sizes.

```{r}
mod_2 <- brm(
  hosp_yn ~ age_group + race + (1 | res_state),
  data = df_recode,
  iter = 2500,
  chains = 4,
  cores = getOption("mc.cores", 4),
  family = bernoulli
)
```

### Results summary

```{r}
summary(mod_2)

```
```{r}
library(kableExtra)

# Data for Model

library(dplyr)
library(kableExtra)
library(htmltools)

# Data for Multilevel Hyperparameters
hyperparameters <- data.frame(
  Parameter = "sd(Intercept)",
  Estimate = 1.65,
  Est_Error = 0.22,
  `l-95% CI` = 1.27,
  `u-95% CI` = 2.13,
  Rhat = 1.00,
  Bulk_ESS = 908,
  Tail_ESS = 1355
)

# Data for Regression Coefficients
coefficients <- data.frame(
  Parameter = c("Intercept", "age_group.L", "age_group.Q", "age_group.C",
                "raceAsian", "raceBlack", "raceMultipleDOther", "raceWhite"),
  Estimate = c(-2.12, 2.28, 0.20, -0.04, -0.30, 0.09, -0.67, -0.51),
  Est_Error = c(0.31, 0.09, 0.08, 0.07, 0.32, 0.20, 0.37, 0.19),
  `l-95% CI` = c(-2.73, 2.09, 0.04, -0.16, -0.92, -0.30, -1.42, -0.88),
  `u-95% CI` = c(-1.48, 2.47, 0.35, 0.09, 0.31, 0.49, 0.04, -0.13),
  Rhat = c(1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00),
  Bulk_ESS = c(610, 4981, 5491, 6164, 3416, 2190, 3385, 2143),
  Tail_ESS = c(1093, 3745, 3889, 3199, 3785, 3097, 3336, 2744)
)

# Create a single combined table
combined_table <- bind_rows(
  data.frame(Table = "Multilevel Hyperparameters", hyperparameters),
  data.frame(Table = "Regression Coefficients", coefficients)
)

# Render the combined table
final_table <- combined_table %>%
  kable(format = "html", caption = "Combined Model Output") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  pack_rows("Multilevel Hyperparameters", 1, 1) %>%
  pack_rows("Regression Coefficients", 2, nrow(combined_table))

# View in RStudio Viewer
htmltools::browsable(final_table)
```

```{r}
posterior = as.array(mod_2)
mcmc_intervals(posterior, pars = c("Intercept", "b_age_group.L", "b_age_group.Q", "b_age_group.C","b_raceAsian", "b_raceBlack", "b_raceMultipleDOther", "b_raceWhite"))
```


### Explore conditional effects of model

```{r}
conditional_effects(mod_2)
```

Age clearly increases risk, but after adjusting for age, race not so much.

### Posterior predictive check of model estimating probability

```{r}
pp_check(mod_2, type = "stat")
```

### Show results by state

epred draws from the expectation of the posterior predictive distribution. Is that correct?

```{r}
# Get observed hospitalization proportions by state (complete cases)
obs_hosp <- df_recode |>
  select(age_group, race, res_state, hosp_yn) |>
  na.omit() |>
  reframe(prop = sum(hosp_yn == "Yes") / n(), .by = "res_state")

obs_y_mean <- df_recode |>
  reframe(mean = mean(hosp_yn == "Yes", na.rm = TRUE)) |>
  pull(mean)

# Show a plot by state, with predictions and observed values
df_recode |>
  data_grid(res_state, age_group, race) |>
  add_epred_draws(mod_2, allow_new_levels = TRUE) |>
  ggplot(aes(x = .epred, y = res_state)) +
    stat_pointinterval() +
    scale_y_discrete(limits = rev) +
    geom_point(data = obs_hosp, aes(x = prop, y = res_state), color = "green") +
    geom_vline(aes(xintercept = obs_y_mean), color = "green")
```

Vertical line represents the overall mean across all states (with missing removed).

### Show a state with high predicted value (Arkansas)

```{r}
df_recode |>
  select(age_group, race, res_state, hosp_yn) |>
  filter(res_state == "AR", 
         is.na(hosp_yn) == FALSE, 
         (is.na(age_group) == FALSE | is.na(race) == FALSE)
         )
```

<<<<<<< HEAD
There were \<20 cases with complete variables, and most were hospitalized.
=======
There were <20 cases with complete variables, and most were hospitalized.

## Consider Second Approach for Missing Data

Using mice supports multiple imputation before model fitting.

With `brm_multiple` one can run the same brms model on multiple datasets and then combine the results into one fitted model object. 

Reference (vignette): https://cran.r-project.org/web/packages/brms/vignettes/brms_missings.html

```{r}

# First select columns we'll need for our formula (only)
df_selected <- df_recode |>
  select(hosp_yn, age_group, race, res_state)

# Do imputation first before modeling
imp <- mice(
  data = df_selected, 
  m = 5                    # Number of sets, default is 5, may need more, but computationally burdensome
)

# Now model with brm_multiple
mod_3 <- brm_multiple(
  hosp_yn ~ age_group + race + (1 | res_state),
  data = imp,
  iter = 1000,
  chains = 4,
  cores = getOption("mc.cores", 4),
  family = bernoulli
)
```

### Summary

```{r}
summary(mod_3)
```

### Plot

```{r}
plot(mod_3)
```

The results are not very good, with high Rhat and low ESS.

Apparently, for models based on multiple imputed data sets, one can get false positives. Chains of different sub-models may not overlay each other exactly, since there were fitted to different data. 

### Separate Model Check for Convergence

```{r}
draws <- as_draws_array(mod_3)

nc <- nchains(mod_3) / 5

draws_per_dat <- lapply(1:5, 
  \(i) subset_draws(draws, chain = ((i-1)*nc+1):(i*nc))
)

lapply(draws_per_dat, summarise_draws, default_convergence_measures())
```

These results are not perfect but better.

## Map Demonstration

```{r}

# Using model 2 for this, but can modify later
map_df <- df_recode |>
  data_grid(res_state, age_group, race) |>
  add_epred_draws(mod_2, allow_new_levels = TRUE) |>
  ungroup() |>
  reframe(pct = mean(.epred) * 100, .by = res_state)

# Change name for merging easily
map_data <- us_map() |>
  rename(res_state = "abbr")

# Merge model data with map data
merged_data <- left_join(map_data, map_df, by = "res_state")

# Make a map
ggplot() +
  geom_sf(data = merged_data,
          aes(fill = pct),
          color = "black",
          linewidth = 0.2) +
  theme_classic() + 
  scale_fill_gradient(low = "lightblue", 
                      high = "darkblue", 
                      name = "Percent Hospitalized") +
  labs(title = "Percent Hospitalized by State") +
  theme(plot.title = element_text(hjust = 0.5))

# Rank by number of hospitalizations in complete cases by state
df_recode |>
  select(hosp_yn, res_state) |>
  na.omit() |>
  reframe(pct = sum(hosp_yn == "Yes", na.rm = TRUE) / n(), n = n(), .by = res_state) |>
  arrange(n)
```

The data from states with low numbers (after missing removed) explains high percentages.

>>>>>>> f4a720574d2758316bcad673237d5231a2b14432
